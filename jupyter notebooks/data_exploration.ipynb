{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression,Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cargamos los datos de entrenamiento\n",
    "train_df = pd.read_csv(\"data/original/Dataset_Salesforce_Predictive_Modelling_TRAIN.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un ejemplo de los datos con los que contamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la variable dependiente.\n",
    "Miremos con más detenimiento la variable a predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df[\"Poder_Adquisitivo\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df[\"Poder_Adquisitivo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % train_df[\"Poder_Adquisitivo\"].skew())\n",
    "print(\"Kurtosis: %f\" % train_df[\"Poder_Adquisitivo\"].kurt())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tal y como se puede observar en el gráfico, esta variable presenta valores extremos de skewness y kurtosis, que se manifiestan en la larga cola derecha que presenta. Esto quiere decir que existe algunos clientes que presentan valores extremadamente altos de poder adquisito que están muy lejos del resto. Será necesario tener en cuenta este hecho para evitar que los valores extremos puedan afectar negativamente a nuestro sistema.\n",
    "\n",
    "Veamos de manera más detallada aquellos valores que tradicionalmente no se considerarían outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = train_df[\"Poder_Adquisitivo\"].quantile(0.25)\n",
    "q3 = train_df[\"Poder_Adquisitivo\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "fence_low  = q1 - 1.5 * iqr\n",
    "fence_high = q3 + 1.5 * iqr\n",
    "\n",
    "train_df_no_outliers = train_df.loc[(train_df[\"Poder_Adquisitivo\"] > fence_low) & (train_df[\"Poder_Adquisitivo\"] < fence_high)]\n",
    "sns.distplot(train_df_no_outliers[\"Poder_Adquisitivo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % train_df_no_outliers[\"Poder_Adquisitivo\"].skew())\n",
    "print(\"Kurtosis: %f\" % train_df_no_outliers[\"Poder_Adquisitivo\"].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien puede que sea necesario estudiar más si esta es la manera más óptima de tratar los valores extremos, ahora presenta unos valores de skewness y kurtosis mucho más aceptables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de las variables independientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las variables \"independientes\", sabemos que contamos con algunas que son de tipo categórico en vez de númerico. Empezemos explorando estas variables y preparandolas para su posterior uso.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Socio_Demo_01\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Socio_Demo_02\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulta inmediato convertir la segunda variable en un formato one-hot listo para ser usado por nuestros modelos. Más díficil es el caso de Socio_Dema_01 que cuenta que muchos valores que solo aparecen un número muy bajo de veces. Una primera aproximación puede ser usar por ejemplo los primeros 10 valores solo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_socio_01 = train_df[\"Socio_Demo_01\"].value_counts()[:10]\n",
    "topk_socio_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos si estas dos variables guardan alguna relación que se pueda ver a primera vista respecto al Poder adquisitivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=train_df_no_outliers[\"Socio_Demo_02\"],y=train_df_no_outliers[\"Poder_Adquisitivo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socio_01_keys = list(topk_socio_01.keys())\n",
    "condition_array = [False] * len(train_df_no_outliers[\"Socio_Demo_01\"])\n",
    "for i in range(len(condition_array)):\n",
    "    condition_array[i] = str(train_df_no_outliers[\"Socio_Demo_01\"].iloc[i]) in socio_01_keys\n",
    "\n",
    "sns.violinplot(x=train_df_no_outliers[\"Socio_Demo_01\"].loc[condition_array],y=train_df_no_outliers[\"Poder_Adquisitivo\"].loc[condition_array])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de datos\n",
    "Con todo lo visto anteriormente estamos listos para preparar los datos para la experimentación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df_1(df,train = True):\n",
    "    df = df.drop(labels=[\"ID_Customer\"],axis=1)\n",
    "    \n",
    "    if train:\n",
    "        #Remove putliers\n",
    "        q1 = df[\"Poder_Adquisitivo\"].quantile(0.25)\n",
    "        q3 = df[\"Poder_Adquisitivo\"].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        fence_low  = q1 - 1.5 * iqr\n",
    "        fence_high = q3 + 1.5 * iqr\n",
    "\n",
    "        df = df.loc[(df[\"Poder_Adquisitivo\"] > fence_low) & (df[\"Poder_Adquisitivo\"] < fence_high)]\n",
    "    \n",
    "        \n",
    "    \n",
    "    #Convert to one-hot\n",
    "\n",
    "    #Socio_Demo_02\n",
    "    c1=df[\"Socio_Demo_02\"] == 1\n",
    "    c2=df[\"Socio_Demo_02\"] == 2\n",
    "    df.insert(loc=len(df.columns), column=\"Socio_Demo_02_01\", value=c1.astype(int))\n",
    "    df.insert(loc=len(df.columns), column=\"Socio_Demo_02_02\", value=c2.astype(int))\n",
    "    \n",
    "    df = df.drop(axis=1, columns=[\"Socio_Demo_02\"])\n",
    "\n",
    "    # Socio_Demo_01\n",
    "    for key in socio_01_keys:\n",
    "        on = df[\"Socio_Demo_01\"] == key\n",
    "        df.insert(loc=len(df.columns), column=\"Socio_Demo_01_\"+key, value=on.astype(int))\n",
    "    \n",
    "    # Add option other\n",
    "    condition_array = [False] * len(df[\"Socio_Demo_01\"])\n",
    "    for i in range(len(condition_array)):\n",
    "        condition_array[i] = str(df[\"Socio_Demo_01\"].iloc[i]) not in socio_01_keys\n",
    "    df.insert(loc=len(df.columns), column=\"Socio_Demo_01_Other\", value=condition_array)\n",
    "    df[\"Socio_Demo_01_Other\"] = df[\"Socio_Demo_01_Other\"].astype(int)\n",
    "    \n",
    "    df = df.drop(axis=1, columns=[\"Socio_Demo_01\"])\n",
    "    \n",
    "    # Ind_prod for now is kept as it is right now\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 4\n",
    "K = 10\n",
    "\n",
    "#Primero shuffleamos los datos\n",
    "shuffled_data = train_df.sample(frac=1,replace=False,random_state=SEED)\n",
    "\n",
    "kf = KFold(n_splits=K)\n",
    "kf.get_n_splits(shuffled_data)\n",
    "\n",
    "# Split and process data\n",
    "splits=[]\n",
    "for train_index, test_index in kf.split(shuffled_data):\n",
    "    train_data = shuffled_data.loc[train_index]\n",
    "    test_data = shuffled_data.loc[test_index]\n",
    "    \n",
    "    train_data_proc = process_df_1(train_data_c,train=True)\n",
    "    test_data_proc = process_df_1(test_data,train=False)\n",
    "\n",
    "    \n",
    "    splits.append((train_data_proc,test_data_proc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model,splits):\n",
    "    rmse = []\n",
    "    mae = []\n",
    "    for s in range(len(splits)):\n",
    "        train_data_proc,test_data_proc = splits[s]\n",
    "        \n",
    "        x_train = train_data_proc.drop(labels=[\"Poder_Adquisitivo\"],axis=1).as_matrix()\n",
    "        y_train = train_data_proc[\"Poder_Adquisitivo\"].as_matrix()\n",
    "\n",
    "\n",
    "        x_test = test_data_proc.drop(labels=[\"Poder_Adquisitivo\"], axis=1).as_matrix()\n",
    "        y_test = test_data_proc[\"Poder_Adquisitivo\"].as_matrix()\n",
    "        \n",
    "        model.fit(X=x_train,y=y_train)\n",
    "        yhat = model.predict(X=x_test)\n",
    "        \n",
    "        rmse.append(math.sqrt(mean_squared_error(y_true=y_test, y_pred=yhat)))\n",
    "        mae.append(mean_absolute_error(y_true=y_test,y_pred=yhat))\n",
    "    return (rmse,mae)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "scores_rmse,scores_mae = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#### YOUR MODEL HERE ###\n",
    "########################\n",
    "\n",
    "# model = YourModel()\n",
    "scores_rmse,scores_mae = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
