{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,median_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (83) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos de entrenamiento\n",
    "train_df = pd.read_csv(\"data/original/Dataset_Salesforce_Predictive_Modelling_TRAIN.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un ejemplo de los datos con los que contamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Customer</th>\n",
       "      <th>Imp_Cons_01</th>\n",
       "      <th>Imp_Cons_02</th>\n",
       "      <th>Imp_Cons_03</th>\n",
       "      <th>Imp_Cons_04</th>\n",
       "      <th>Imp_Cons_05</th>\n",
       "      <th>Imp_Cons_06</th>\n",
       "      <th>Imp_Cons_07</th>\n",
       "      <th>Imp_Cons_08</th>\n",
       "      <th>Imp_Cons_09</th>\n",
       "      <th>...</th>\n",
       "      <th>Num_Oper_17</th>\n",
       "      <th>Num_Oper_18</th>\n",
       "      <th>Num_Oper_19</th>\n",
       "      <th>Num_Oper_20</th>\n",
       "      <th>Socio_Demo_01</th>\n",
       "      <th>Socio_Demo_02</th>\n",
       "      <th>Socio_Demo_03</th>\n",
       "      <th>Socio_Demo_04</th>\n",
       "      <th>Socio_Demo_05</th>\n",
       "      <th>Poder_Adquisitivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TR000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.067778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.196667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>09991</td>\n",
       "      <td>1</td>\n",
       "      <td>70.44</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>19709.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TR000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.58</td>\n",
       "      <td>595.454545</td>\n",
       "      <td>10.899000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.473636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.268571</td>\n",
       "      <td>42.61</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>09991</td>\n",
       "      <td>2</td>\n",
       "      <td>71.87</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>37497.492167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TR000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0X301</td>\n",
       "      <td>2</td>\n",
       "      <td>72.48</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>4802.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TR000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0X301</td>\n",
       "      <td>2</td>\n",
       "      <td>86.60</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>8295.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TR000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>09991</td>\n",
       "      <td>2</td>\n",
       "      <td>92.48</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>24149.321667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_Customer  Imp_Cons_01  Imp_Cons_02  Imp_Cons_03  Imp_Cons_04  \\\n",
       "0    TR000001          0.0         0.00     0.000000    63.067778   \n",
       "1    TR000002          0.0       100.58   595.454545    10.899000   \n",
       "2    TR000003          0.0         0.00     0.000000     0.000000   \n",
       "3    TR000004          0.0         0.00     0.000000     0.000000   \n",
       "4    TR000005          0.0         0.00     0.000000     0.000000   \n",
       "\n",
       "   Imp_Cons_05  Imp_Cons_06  Imp_Cons_07  Imp_Cons_08  Imp_Cons_09  \\\n",
       "0          0.0    52.196667          0.0     0.000000         0.00   \n",
       "1          0.0    39.473636          0.0    62.268571        42.61   \n",
       "2          0.0     0.000000          0.0     0.000000         0.00   \n",
       "3          0.0     0.000000          0.0     0.000000         0.00   \n",
       "4          0.0     0.000000          0.0     0.000000         0.00   \n",
       "\n",
       "         ...          Num_Oper_17  Num_Oper_18  Num_Oper_19  Num_Oper_20  \\\n",
       "0        ...                    2            0            0            0   \n",
       "1        ...                    4            1            0            0   \n",
       "2        ...                    2            0            0            0   \n",
       "3        ...                    0            0            0            0   \n",
       "4        ...                    0            0            0            0   \n",
       "\n",
       "   Socio_Demo_01  Socio_Demo_02  Socio_Demo_03  Socio_Demo_04  Socio_Demo_05  \\\n",
       "0          09991              1          70.44              3             20   \n",
       "1          09991              2          71.87              3             29   \n",
       "2          0X301              2          72.48              2             41   \n",
       "3          0X301              2          86.60              3             38   \n",
       "4          09991              2          92.48              4             35   \n",
       "\n",
       "   Poder_Adquisitivo  \n",
       "0       19709.915000  \n",
       "1       37497.492167  \n",
       "2        4802.970000  \n",
       "3        8295.770000  \n",
       "4       24149.321667  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID_Customer', 'Imp_Cons_01', 'Imp_Cons_02', 'Imp_Cons_03',\n",
       "       'Imp_Cons_04', 'Imp_Cons_05', 'Imp_Cons_06', 'Imp_Cons_07',\n",
       "       'Imp_Cons_08', 'Imp_Cons_09', 'Imp_Cons_10', 'Imp_Cons_11',\n",
       "       'Imp_Cons_12', 'Imp_Cons_13', 'Imp_Cons_14', 'Imp_Cons_15',\n",
       "       'Imp_Cons_16', 'Imp_Cons_17', 'Imp_Sal_01', 'Imp_Sal_02', 'Imp_Sal_03',\n",
       "       'Imp_Sal_04', 'Imp_Sal_05', 'Imp_Sal_06', 'Imp_Sal_07', 'Imp_Sal_08',\n",
       "       'Imp_Sal_09', 'Imp_Sal_10', 'Imp_Sal_11', 'Imp_Sal_12', 'Imp_Sal_13',\n",
       "       'Imp_Sal_14', 'Imp_Sal_15', 'Imp_Sal_16', 'Imp_Sal_17', 'Imp_Sal_18',\n",
       "       'Imp_Sal_19', 'Imp_Sal_20', 'Imp_Sal_21', 'Ind_Prod_01', 'Ind_Prod_02',\n",
       "       'Ind_Prod_03', 'Ind_Prod_04', 'Ind_Prod_05', 'Ind_Prod_06',\n",
       "       'Ind_Prod_07', 'Ind_Prod_08', 'Ind_Prod_09', 'Ind_Prod_10',\n",
       "       'Ind_Prod_11', 'Ind_Prod_12', 'Ind_Prod_13', 'Ind_Prod_14',\n",
       "       'Ind_Prod_15', 'Ind_Prod_16', 'Ind_Prod_17', 'Ind_Prod_18',\n",
       "       'Ind_Prod_19', 'Ind_Prod_20', 'Ind_Prod_21', 'Ind_Prod_22',\n",
       "       'Ind_Prod_23', 'Ind_Prod_24', 'Num_Oper_01', 'Num_Oper_02',\n",
       "       'Num_Oper_03', 'Num_Oper_04', 'Num_Oper_05', 'Num_Oper_06',\n",
       "       'Num_Oper_07', 'Num_Oper_08', 'Num_Oper_09', 'Num_Oper_10',\n",
       "       'Num_Oper_11', 'Num_Oper_12', 'Num_Oper_13', 'Num_Oper_14',\n",
       "       'Num_Oper_15', 'Num_Oper_16', 'Num_Oper_17', 'Num_Oper_18',\n",
       "       'Num_Oper_19', 'Num_Oper_20', 'Socio_Demo_01', 'Socio_Demo_02',\n",
       "       'Socio_Demo_03', 'Socio_Demo_04', 'Socio_Demo_05', 'Poder_Adquisitivo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_Customer           object\n",
       "Imp_Cons_01          float64\n",
       "Imp_Cons_02          float64\n",
       "Imp_Cons_03          float64\n",
       "Imp_Cons_04          float64\n",
       "Imp_Cons_05          float64\n",
       "Imp_Cons_06          float64\n",
       "Imp_Cons_07          float64\n",
       "Imp_Cons_08          float64\n",
       "Imp_Cons_09          float64\n",
       "Imp_Cons_10          float64\n",
       "Imp_Cons_11          float64\n",
       "Imp_Cons_12          float64\n",
       "Imp_Cons_13          float64\n",
       "Imp_Cons_14          float64\n",
       "Imp_Cons_15          float64\n",
       "Imp_Cons_16          float64\n",
       "Imp_Cons_17          float64\n",
       "Imp_Sal_01           float64\n",
       "Imp_Sal_02           float64\n",
       "Imp_Sal_03           float64\n",
       "Imp_Sal_04           float64\n",
       "Imp_Sal_05           float64\n",
       "Imp_Sal_06           float64\n",
       "Imp_Sal_07           float64\n",
       "Imp_Sal_08           float64\n",
       "Imp_Sal_09           float64\n",
       "Imp_Sal_10           float64\n",
       "Imp_Sal_11           float64\n",
       "Imp_Sal_12           float64\n",
       "                      ...   \n",
       "Ind_Prod_21            int64\n",
       "Ind_Prod_22            int64\n",
       "Ind_Prod_23            int64\n",
       "Ind_Prod_24            int64\n",
       "Num_Oper_01            int64\n",
       "Num_Oper_02            int64\n",
       "Num_Oper_03            int64\n",
       "Num_Oper_04            int64\n",
       "Num_Oper_05            int64\n",
       "Num_Oper_06            int64\n",
       "Num_Oper_07            int64\n",
       "Num_Oper_08            int64\n",
       "Num_Oper_09            int64\n",
       "Num_Oper_10            int64\n",
       "Num_Oper_11            int64\n",
       "Num_Oper_12            int64\n",
       "Num_Oper_13            int64\n",
       "Num_Oper_14            int64\n",
       "Num_Oper_15            int64\n",
       "Num_Oper_16            int64\n",
       "Num_Oper_17            int64\n",
       "Num_Oper_18            int64\n",
       "Num_Oper_19            int64\n",
       "Num_Oper_20            int64\n",
       "Socio_Demo_01         object\n",
       "Socio_Demo_02          int64\n",
       "Socio_Demo_03        float64\n",
       "Socio_Demo_04          int64\n",
       "Socio_Demo_05          int64\n",
       "Poder_Adquisitivo    float64\n",
       "Length: 89, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la variable dependiente.\n",
    "Miremos con más detenimiento la variable a predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df[\"Poder_Adquisitivo\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df[\"Poder_Adquisitivo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % train_df[\"Poder_Adquisitivo\"].skew())\n",
    "print(\"Kurtosis: %f\" % train_df[\"Poder_Adquisitivo\"].kurt())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tal y como se puede observar en el gráfico, esta variable presenta valores extremos de skewness y kurtosis, que se manifiestan en la larga cola derecha que presenta. Esto quiere decir que existe algunos clientes que presentan valores extremadamente altos de poder adquisito que están muy lejos del resto. Será necesario tener en cuenta este hecho para evitar que los valores extremos puedan afectar negativamente a nuestro sistema.\n",
    "\n",
    "Veamos de manera más detallada aquellos valores que tradicionalmente no se considerarían outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = train_df[\"Poder_Adquisitivo\"].quantile(0.25)\n",
    "q3 = train_df[\"Poder_Adquisitivo\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "fence_low  = q1 - 1.5 * iqr\n",
    "fence_high = q3 + 1.5 * iqr\n",
    "\n",
    "train_df_no_outliers = train_df.loc[(train_df[\"Poder_Adquisitivo\"] > fence_low) & (train_df[\"Poder_Adquisitivo\"] < fence_high)]\n",
    "sns.distplot(train_df_no_outliers[\"Poder_Adquisitivo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % train_df_no_outliers[\"Poder_Adquisitivo\"].skew())\n",
    "print(\"Kurtosis: %f\" % train_df_no_outliers[\"Poder_Adquisitivo\"].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien puede que sea necesario estudiar más si esta es la manera más óptima de tratar los valores extremos, ahora presenta unos valores de skewness y kurtosis mucho más aceptables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de las variables independientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las variables \"independientes\", sabemos que contamos con algunas que son de tipo categórico en vez de númerico. Empezemos explorando estas variables y preparandolas para su posterior uso.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df_no_outliers[\"Socio_Demo_01\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar como Socio_Demo_01 que cuenta que muchos valores que solo aparecen un número muy bajo de veces. A la hora de transformar para su uso, es probable que la inclusión de los 921 valores posibles no aporte información discriminativa y solo sirva para aumentar el número de dimensiones. Una primera aproximación que mantenga un equilibrio entre complejidad y utilidad puede ser usar solo un número de estos valores, aquellos que aparezcan un mayor número de veces, y condensar el resto en una categoría \"Other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_socio_01 = train_df_no_outliers[\"Socio_Demo_01\"].value_counts()[:10]\n",
    "topk_socio_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socio_01_keys = list(topk_socio_01.keys())\n",
    "condition_array = [False] * len(train_df_no_outliers[\"Socio_Demo_01\"])\n",
    "for i in range(len(condition_array)):\n",
    "    condition_array[i] = str(train_df_no_outliers[\"Socio_Demo_01\"].iloc[i]) in socio_01_keys\n",
    "\n",
    "sns.violinplot(x=train_df_no_outliers[\"Socio_Demo_01\"].loc[condition_array],y=train_df_no_outliers[\"Poder_Adquisitivo\"].loc[condition_array])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es interesante ver como algunos valores como 09992 parecen concentrar la mayor parte de clientes en valores diferentes del resto, lo cual puede aportar información importante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_no_outliers[\"Socio_Demo_02\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=train_df_no_outliers[\"Socio_Demo_02\"],y=train_df_no_outliers[\"Poder_Adquisitivo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo la distribución de valores (61%/41%), y que las diferencias entre ambos valores no parecen muy grandes, en nuestra opinión es una opción probable que este variable represente el **sexo** del cliente.\n",
    "\n",
    "Veamos el resto de variables socio demográficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df_no_outliers[\"Socio_Demo_03\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=train_df_no_outliers[\"Socio_Demo_03\"], y=train_df_no_outliers[\"Poder_Adquisitivo\"],kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos algunas agrupaciones interesantes, estudiemoslas en mayor profundidad,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = train_df_no_outliers.loc[ train_df_no_outliers[\"Socio_Demo_03\"] <= 45 ]\n",
    "c2 = train_df_no_outliers.loc[ (train_df_no_outliers[\"Socio_Demo_03\"] > 45 ) & (train_df_no_outliers[\"Socio_Demo_03\"] <= 65) ]\n",
    "c3 = train_df_no_outliers.loc[ (train_df_no_outliers[\"Socio_Demo_03\"] > 65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=c1[\"Socio_Demo_03\"], y=train_df_no_outliers[\"Poder_Adquisitivo\"],kind='hex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=c2[\"Socio_Demo_03\"], y=train_df_no_outliers[\"Poder_Adquisitivo\"],kind='hex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=c3[\"Socio_Demo_03\"], y=train_df_no_outliers[\"Poder_Adquisitivo\"],kind='hex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sería posible estudiar si es posible extraer alguna feature interesante a partir de esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df_no_outliers[\"Socio_Demo_04\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_no_outliers[\"Socio_Demo_04\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=train_df_no_outliers[\"Socio_Demo_04\"], y=train_df_no_outliers[\"Poder_Adquisitivo\"],kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df_no_outliers[\"Socio_Demo_05\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=train_df_no_outliers[\"Socio_Demo_05\"], y=train_df_no_outliers[\"Poder_Adquisitivo\"],kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de datos\n",
    "Con todo lo visto anteriormente estamos listos para preparar los datos para la experimentación. Preparamos una función para realizar un preproceso general, y definimos dos tipos.\n",
    "El preproceso 0 consiste simplemente en convertir los valores a one-hot, mientras que en el preproceso 1 eliminamos los outliers de \"Poder_Adquisitivo\" que hemos detectado antes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df,processing_type,train = True):\n",
    "    if processing_type == 1:\n",
    "        return process_df_1(df,train)\n",
    "    elif processing_type == 2:\n",
    "        return process_df_2(df,train)\n",
    "    else:\n",
    "        return process_df_0(df)\n",
    "\n",
    "def process_df_0(df):\n",
    "    return process_df_1(df,False)\n",
    "    \n",
    "def process_df_1(df,train = True):\n",
    "    df = df.drop(labels=[\"ID_Customer\"],axis=1)\n",
    "    \n",
    "    if train:\n",
    "        #Remove putliers\n",
    "        q1 = df[\"Poder_Adquisitivo\"].quantile(0.25)\n",
    "        q3 = df[\"Poder_Adquisitivo\"].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        fence_low  = q1 - 1.5 * iqr\n",
    "        fence_high = q3 + 1.5 * iqr\n",
    "\n",
    "        df = df.loc[(df[\"Poder_Adquisitivo\"] > fence_low) & (df[\"Poder_Adquisitivo\"] < fence_high)]\n",
    "    \n",
    "        \n",
    "    \n",
    "    #Convert to one-hot\n",
    "\n",
    "    # Socio_Demo_01\n",
    "    \n",
    "    topk_socio_01 = df[\"Socio_Demo_01\"].value_counts()[:10]\n",
    "    socio_01_keys = list(topk_socio_01.keys())\n",
    "    \n",
    "    for key in socio_01_keys:\n",
    "        on = df[\"Socio_Demo_01\"] == key\n",
    "        df.insert(loc=len(df.columns), column=\"Socio_Demo_01_\"+str(key), value=on.astype(int))\n",
    "    \n",
    "    # Add option other\n",
    "    condition_array = [False] * len(df[\"Socio_Demo_01\"])\n",
    "    for i in range(len(condition_array)):\n",
    "        condition_array[i] = str(df[\"Socio_Demo_01\"].iloc[i]) not in socio_01_keys\n",
    "    df.insert(loc=len(df.columns), column=\"Socio_Demo_01_Other\", value=condition_array)\n",
    "    df[\"Socio_Demo_01_Other\"] = df[\"Socio_Demo_01_Other\"].astype(int)\n",
    "    \n",
    "    df = df.drop(axis=1, columns=[\"Socio_Demo_01\"])\n",
    "    \n",
    "    # Socio_Demo_02\n",
    "    c1=df[\"Socio_Demo_02\"] == 1\n",
    "    c2=df[\"Socio_Demo_02\"] == 2\n",
    "    df.insert(loc=len(df.columns), column=\"Socio_Demo_02_01\", value=c1.astype(int))\n",
    "    df.insert(loc=len(df.columns), column=\"Socio_Demo_02_02\", value=c2.astype(int))\n",
    "    \n",
    "    df = df.drop(axis=1, columns=[\"Socio_Demo_02\"])\n",
    "\n",
    "    \n",
    "    # Ind_prod for now is kept as it is right now\n",
    "    \n",
    "    for i in range(1,25):\n",
    "        column_name = \"Ind_Prod_\" + str(i).zfill(2)\n",
    "        c0=df[column_name] == 0\n",
    "        c1=df[column_name] == 1\n",
    "        c2=df[column_name] == 2\n",
    "        \n",
    "        df.insert(loc=len(df.columns), column=column_name + \"_00\", value=c0.astype(int))\n",
    "        df.insert(loc=len(df.columns), column=column_name + \"_01\", value=c1.astype(int))\n",
    "        df.insert(loc=len(df.columns), column=column_name + \"_02\", value=c2.astype(int))\n",
    "    \n",
    "        df = df.drop(axis=1, columns=[column_name])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_df_2(df,train = True):\n",
    "    df = process_df_1(df,train)\n",
    "    \n",
    "    # Socio_Demo_03\n",
    "    c1 = df[\"Socio_Demo_03\"] <= 45 \n",
    "    c2 = (df[\"Socio_Demo_03\"] > 45 ) & (df[\"Socio_Demo_03\"] <= 65) \n",
    "    c3 = df[\"Socio_Demo_03\"] > 65\n",
    "    \n",
    "    df.insert(loc=len(df.columns), column=\"Socio_Demo_03_c1\", value=c1.astype(int))\n",
    "    df.insert(loc=len(df.columns), column=\"Socio_Demo_03_c2\", value=c2.astype(int))\n",
    "    df.insert(loc=len(df.columns), column=\"Socio_Demo_03_c3\", value=c3.astype(int))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora a barajar los datos, y a realizar una partición en KFolds, para poder realizar un análisis de resultados de manera correcta y fiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 4\n",
    "K = 5\n",
    "\n",
    "shuffled_data = train_df.sample(frac=1,replace=False,random_state=SEED)\n",
    "\n",
    "kf = KFold(n_splits=K)\n",
    "kf.get_n_splits(shuffled_data)\n",
    "\n",
    "def get_splits(kf,processing_type):\n",
    "    splits=[]\n",
    "    for train_index, test_index in kf.split(shuffled_data):\n",
    "        train_data = shuffled_data.loc[train_index]\n",
    "        test_data = shuffled_data.loc[test_index]\n",
    "\n",
    "        train_data_proc = process_df(train_data,processing_type,train=True)\n",
    "        test_data_proc = process_df(test_data,processing_type,train=False)\n",
    "\n",
    "\n",
    "        splits.append((train_data_proc,test_data_proc))\n",
    "    return splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un modelo y los splits que hemos realizado a los datos, definimos una función que, para cada partición de entrenamiento y test, entrene un modelo con los datos de entrenamiento correspondiente y calcule métricas sobre el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model,splits):\n",
    "    rmse = []\n",
    "    mae = []\n",
    "    mad = []\n",
    "    for s in range(len(splits)):\n",
    "        train_data_proc,test_data_proc = splits[s]\n",
    "        \n",
    "        x_train = train_data_proc.drop(labels=[\"Poder_Adquisitivo\"],axis=1).as_matrix()\n",
    "        y_train = train_data_proc[\"Poder_Adquisitivo\"].as_matrix()\n",
    "\n",
    "\n",
    "        x_test = test_data_proc.drop(labels=[\"Poder_Adquisitivo\"], axis=1).as_matrix()\n",
    "        y_test = test_data_proc[\"Poder_Adquisitivo\"].as_matrix()\n",
    "        \n",
    "        model.fit(X=x_train,y=y_train)\n",
    "        yhat = model.predict(X=x_test)\n",
    "        \n",
    "        rmse.append(math.sqrt(mean_squared_error(y_true=y_test, y_pred=yhat)))\n",
    "        mae.append(mean_absolute_error(y_true=y_test,y_pred=yhat))\n",
    "        mad.append(median_absolute_error(y_true=y_test,y_pred=yhat))\n",
    "        \n",
    "    return (rmse,mae,mad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos primero con todos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "splits = get_splits(kf,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor(max_iter=200,hidden_layer_sizes=(25,25,25),early_stopping=True,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos ahora los resultados sobre datos de los que hemos **eliminado outliers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "splits = get_splits(kf,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 21866.239828\n",
      "MAE: 5257.209822\n",
      "MAD: 3039.409075\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso(max_iter=200,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(max_iter=200,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet(max_iter=200,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los modelos lineales parecen obtener resultados comparables. Probemos otro tipo de modelos más avanzados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor(max_iter=200,hidden_layer_sizes=(25,25,25),early_stopping=True,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor(max_iter=200,hidden_layer_sizes=(50,50,50),early_stopping=True,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor(max_iter=200,hidden_layer_sizes=(25,25,25,25),early_stopping=True,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=50, criterion='mse', max_depth=3, max_features='log2',min_samples_leaf=5,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=50, criterion='mse', max_depth=5, max_features='log2',min_samples_leaf=5,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=50, criterion='mse', max_depth=7, max_features='log2',min_samples_leaf=5,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=50, criterion='mse', max_depth=17, max_features='log2',min_samples_leaf=5,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=50, criterion='mse', max_depth=21, max_features='log2',min_samples_leaf=5,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=50, criterion='mse', max_depth=23, max_features='auto',min_samples_leaf=5,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now try different Gradient boosting models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ones seem to take quite a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(random_state=SEED,min_samples_leaf=5)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(random_state=SEED,min_samples_leaf=5,max_depth=5)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 21866.239828\n",
      "MAE: 5257.209822\n",
      "MAD: 3039.409075\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor(max_iter=200,hidden_layer_sizes=(25,25,25),early_stopping=True,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=50, criterion='mse', max_depth=23, max_features='auto',min_samples_leaf=5,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22864.444762\n",
      "MAE: 5282.026237\n",
      "MAD: 2638.862812\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "#### YOUR MODEL HERE ###\n",
    "########################\n",
    "\n",
    "# Acordarse de generar splits, preferentemente con el dataset 1, splits = get_splits(kf,1)\n",
    "\n",
    "# Quitar las comillas que rodean al código y sustituir YourModel() por el modelo que se quiera probar\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22864.074822\n",
      "MAE: 5276.871090\n",
      "MAD: 2631.246229\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsRegressor(n_neighbors=5, weights='distance', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22839.037786\n",
      "MAE: 5211.084402\n",
      "MAD: 2572.456258\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = KNeighborsRegressor(n_neighbors=8, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=2)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8c0af151685b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mRBF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1e-2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianProcessRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscores_rmse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscores_mae\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscores_mad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msplits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RMSE: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_rmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-ef00ab714513>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, splits)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data_proc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Poder_Adquisitivo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    215\u001b[0m             optima = [(self._constrained_optimization(obj_func,\n\u001b[0;32m    216\u001b[0m                                                       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                                       self.kernel_.bounds))]\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;31m# Additional runs are performed from log-uniform chosen initial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py\u001b[0m in \u001b[0;36m_constrained_optimization\u001b[1;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fmin_l_bfgs_b\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[0mtheta_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvergence_dict\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m                 \u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconvergence_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"warnflag\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m                 warnings.warn(\"fmin_l_bfgs_b terminated abnormally with the \"\n",
      "\u001b[1;32mc:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 199\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    201\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py\u001b[0m in \u001b[0;36mobj_func\u001b[1;34m(theta, eval_gradient)\u001b[0m\n\u001b[0;32m    207\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                     lml, grad = self.log_marginal_likelihood(\n\u001b[1;32m--> 209\u001b[1;33m                         theta, eval_gradient=True)\n\u001b[0m\u001b[0;32m    210\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[1;34m(self, theta, eval_gradient)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \"\"\"\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mK1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK1_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m             \u001b[0mK2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK2_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             return K1 * K2, np.dstack((K1_gradient * K2[:, :, np.newaxis],\n",
      "\u001b[1;32mc:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   1000\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Gradient can only be evaluated when Y is None.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1003\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameter_constant_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhon\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mones\u001b[1;34m(shape, dtype, order)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m--> 188\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unsafe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "model = GaussianProcessRegressor(random_state=SEED, kernel = kernel, n_restarts_optimizer=9)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 23053.881152\n",
      "MAE: 5710.700259\n",
      "MAD: 2916.174083\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeRegressor()\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22699.475935\n",
      "MAE: 4846.599782\n",
      "MAD: 2263.298157\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeRegressor(min_samples_split=100, min_samples_leaf=20, random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22675.872660\n",
      "MAE: 4816.143923\n",
      "MAD: 2237.525215\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeRegressor(min_samples_split=100, min_samples_leaf=50, random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22670.479224\n",
      "MAE: 4802.948535\n",
      "MAD: 2223.817397\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeRegressor(min_samples_split=200, min_samples_leaf=50, random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22671.499261\n",
      "MAE: 4805.775760\n",
      "MAD: 2225.222889\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeRegressor(min_samples_split=150, min_samples_leaf=50, random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto son experimntos fallidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "splits = get_splits(kf,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor(max_iter=200,hidden_layer_sizes=(25,25,25),early_stopping=True,random_state=SEED)\n",
    "scores_rmse,scores_mae,scores_mad = train_and_evaluate(model,splits)\n",
    "\n",
    "\n",
    "print(\"RMSE: %f\" % np.mean(scores_rmse))\n",
    "print(\"MAE: %f\" % np.mean(scores_mae))\n",
    "print(\"MAD: %f\" % np.mean(scores_mad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados paracen indicar que ese tipo de data-augmentation ha fallado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
